# NLM
- extract data from at least 2 sources(PDF,WEB,DOCX,TEXT file, Twitter, JSON file, csv file)
- Demonstrate single word tokenization, using regular expression (use findall() function to list meaningful tokens from the source dataset)
- use bs4 python library and demonstrate web scraping for meaningful information
 for example: biodata of top athletes in the world
- Demonstrate Normalization , case conversion using function lower()
- demonstrate removal of stop words and standardization by string replacement
- lemmatize your data using textblob python library
- for your data set compute the word frequency
